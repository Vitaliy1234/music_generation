{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b74a857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting MIDI for /Users/18629082/Desktop/Каэр морхен - 18.06.2022, 22.mp3...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input signal length=0 is too small to resample from 44100->22050",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbasic_pitch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ICASSP_2022_MODEL_PATH\n\u001b[1;32m      4\u001b[0m audio \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/18629082/Desktop/Каэр морхен - 18.06.2022, 22.mp3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m model_output, midi_data, note_activations \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monset_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/music_generation/venv/lib/python3.8/site-packages/basic_pitch/inference.py:303\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(audio_path, model_or_model_path, onset_threshold, frame_threshold, minimum_note_length, minimum_frequency, maximum_frequency, multiple_pitch_bends, melodia_trick, debug_file)\u001b[0m\n\u001b[1;32m    299\u001b[0m     model \u001b[38;5;241m=\u001b[39m model_or_model_path\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicting MIDI for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 303\u001b[0m model_output \u001b[38;5;241m=\u001b[39m \u001b[43mrun_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m min_note_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mround(minimum_note_length \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m*\u001b[39m (AUDIO_SAMPLE_RATE \u001b[38;5;241m/\u001b[39m FFT_HOP)))\n\u001b[1;32m    305\u001b[0m midi_data, note_events \u001b[38;5;241m=\u001b[39m infer\u001b[38;5;241m.\u001b[39mmodel_output_to_notes(\n\u001b[1;32m    306\u001b[0m     model_output,\n\u001b[1;32m    307\u001b[0m     onset_thresh\u001b[38;5;241m=\u001b[39monset_threshold,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m     melodia_trick\u001b[38;5;241m=\u001b[39mmelodia_trick,\n\u001b[1;32m    314\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/music_generation/venv/lib/python3.8/site-packages/basic_pitch/inference.py:144\u001b[0m, in \u001b[0;36mrun_inference\u001b[0;34m(audio_path, model, debug_file)\u001b[0m\n\u001b[1;32m    141\u001b[0m overlap_len \u001b[38;5;241m=\u001b[39m n_overlapping_frames \u001b[38;5;241m*\u001b[39m FFT_HOP\n\u001b[1;32m    142\u001b[0m hop_size \u001b[38;5;241m=\u001b[39m AUDIO_N_SAMPLES \u001b[38;5;241m-\u001b[39m overlap_len\n\u001b[0;32m--> 144\u001b[0m audio_windowed, _, audio_original_length \u001b[38;5;241m=\u001b[39m \u001b[43mget_audio_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlap_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m output \u001b[38;5;241m=\u001b[39m model(audio_windowed)\n\u001b[1;32m    147\u001b[0m unwrapped_output \u001b[38;5;241m=\u001b[39m {k: unwrap_output(output[k], audio_original_length, n_overlapping_frames) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m output}\n",
      "File \u001b[0;32m~/Desktop/music_generation/venv/lib/python3.8/site-packages/basic_pitch/inference.py:90\u001b[0m, in \u001b[0;36mget_audio_input\u001b[0;34m(audio_path, overlap_len, hop_size)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03mRead wave file (as mono), pad appropriately, and return as\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03mwindowed signal, with window length = AUDIO_N_SAMPLES\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m overlap_len \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverlap_length must be even, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(overlap_len)\n\u001b[0;32m---> 90\u001b[0m audio_original, _ \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAUDIO_SAMPLE_RATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmono\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m original_length \u001b[38;5;241m=\u001b[39m audio_original\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     93\u001b[0m audio_original \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mint\u001b[39m(overlap_len \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m),), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32), audio_original])\n",
      "File \u001b[0;32m~/Desktop/music_generation/venv/lib/python3.8/site-packages/librosa/util/decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     91\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[1;32m     94\u001b[0m ]\n",
      "File \u001b[0;32m~/Desktop/music_generation/venv/lib/python3.8/site-packages/librosa/core/audio.py:179\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    176\u001b[0m     y \u001b[38;5;241m=\u001b[39m to_mono(y)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr_native\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     sr \u001b[38;5;241m=\u001b[39m sr_native\n",
      "File \u001b[0;32m~/Desktop/music_generation/venv/lib/python3.8/site-packages/librosa/util/decorators.py:88\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     91\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[1;32m     94\u001b[0m ]\n",
      "File \u001b[0;32m~/Desktop/music_generation/venv/lib/python3.8/site-packages/librosa/core/audio.py:647\u001b[0m, in \u001b[0;36mresample\u001b[0;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m soxr\u001b[38;5;241m.\u001b[39mresample(y\u001b[38;5;241m.\u001b[39mT, orig_sr, target_sr, quality\u001b[38;5;241m=\u001b[39mres_type)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 647\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mresampy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_sr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_sr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fix:\n\u001b[1;32m    650\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mfix_length(y_hat, size\u001b[38;5;241m=\u001b[39mn_samples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/music_generation/venv/lib/python3.8/site-packages/resampy/core.py:117\u001b[0m, in \u001b[0;36mresample\u001b[0;34m(x, sr_orig, sr_new, axis, filter, parallel, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m shape[axis] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(shape[axis] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mfloat\u001b[39m(sr_new) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(sr_orig))\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape[axis] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput signal length=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is too small to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresample from \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m->\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(x\u001b[38;5;241m.\u001b[39mshape[axis], sr_orig, sr_new)\n\u001b[1;32m    120\u001b[0m     )\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Preserve contiguity of input (if it exists)\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(x\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger):\n",
      "\u001b[0;31mValueError\u001b[0m: Input signal length=0 is too small to resample from 44100->22050"
     ]
    }
   ],
   "source": [
    "from basic_pitch.inference import predict\n",
    "from basic_pitch import ICASSP_2022_MODEL_PATH\n",
    "\n",
    "audio = '/Users/18629082/Desktop/Каэр морхен - 18.06.2022, 22.mp3'\n",
    "\n",
    "model_output, midi_data, note_activations = predict(audio, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b66cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dad4de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = librosa.load(audio, sr=None, duration=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57070914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132300"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b12e546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
